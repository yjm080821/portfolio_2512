# ⌚️ Qiri (Apple Watch / iOS App)

## 📌 프로젝트 소개
**Qiri**는 Apple Watch와 iOS를 연동해, **제스처/음성 기반으로 질문**하고 **실시간 스트리밍 답변**을 받을 수 있는 서비스입니다.  
워치 실행 시 iOS와 **사용자 인증/동기화를 자동화**하여, 빠르게 사용할 수 있도록 설계했습니다.

---

## 🎯 프로젝트 목적
- Apple Watch에서 간편하게 질문하고, 즉시 답변을 확인할 수 있는 **웨어러블 AI 경험** 제공
- iOS–Watch 간 사용자 정보 **실시간 동기화**로 로그인/연결 과정을 최소화
- 외부 AI API 의존을 줄이고 **온프레미스 LLM(Qwen3)** 기반으로 개인정보/비용 문제를 개선

---

## 🧠 핵심 기능
### 1) 워치 디바이스 인증 & 사용자 동기화 자동화
- iOS ↔ Watch 앱 **실시간 동기화**
- Watch 앱 실행 시 iOS가 **사용자 정보를 자동 전송**하여 인증/동기화 간소화

### 2) 제스처/음성 기반 상호작용
- Watch에서 **Qiri 호출 → 질문 입력(음성/제스처)** 흐름 지원
- AssistiveTouch 등 제스처 기반 호출 가이드 제공

### 3) 실시간 스트리밍 답변 출력
- 스트리밍 통신 방식으로 **토큰 단위 답변을 실시간 출력**
- **RAG 기반 정보 검색**으로 답변 신뢰성 향상

---

## 🧰 사용 기술 (Tech Stack)
### ✅ 프론트엔드 (iOS / watchOS)
- SwiftUI
- WatchConnectivity
- Moya

### ✅ 백엔드
- Rust / Axum
- PostgreSQL (RDS)
- Redis (ElastiCache)
- AWS (VPC, Private Subnet 구성)

### ✅ AI 서버
- FastAPI
- PyTorch
- Transformers
- AWQ (Quantization)
- Threading

---

## 🏗️ 시스템 아키텍처 요약
- iOS/Watch 앱 → **API Server(AWS, Private Subnet)**
- API Server ↔ **Redis(ElastiCache)** / **PostgreSQL(RDS)**
- AI 추론 서버는 **Tailscale 기반 Private Network**로 연결하여  
  **같은 네트워크에 있는 것처럼(루프백 수준) 안전하게 통신**하도록 구성

---

## 🤖 AI 구성 및 최적화 포인트
### 1) 온프레미스 Qwen3 모델 구축
기존 “타사 AI API” 방식의 단점(외부 의존, 추가 학습 어려움, 개인정보 유출 위험, 비용 대비 성능 문제)을 개선하기 위해  
**온프레미스 환경에 Qwen3 모델을 구축**해 사용했습니다.

### 2) ReAct + RAG (검색 증강)
- 정보 검색/계산 등 외부 환경과 상호작용하는 방식으로
- 더 정확하고 유연한 응답 생성 가능

### 3) 추론 시간 증가(Wait 토큰 활용)
- ‘Wait’ 토큰을 활용해 추론 시간을 늘려
- 적은 학습 데이터로도 높은 성능을 달성하는 접근을 적용

### 4) AWQ Quantization 적용
- 성능을 유지하면서 저비트 양자화
- 성능 하락은 3~4% 수준으로 최소화
- 메모리 사용량 **32GB → 11GB**로 절감(약 4배 효율)

---

## ▶️ 사용 방법 (User Flow)
1. iPhone에서 Qiri 앱 실행 및 Apple 계정 기반 로그인
2. Apple Watch에서 Qiri 앱 실행
3. Watch에서 Qiri를 클릭하거나 AssistiveTouch 제스처로 호출
4. 질문(음성/입력) → AI가 **실시간 스트리밍으로 답변** 제공
5. 답변 확인

---

## 👥 팀 구성 (역할)

* **양지민**: 팀장, AI, 발표 준비(편집)
* **류승엽**: 백엔드, 인프라
* **김은찬**: 프론트엔드, 디자인
* **김동욱**: AI 보조

---

## ✍ 느낀 점

* 워치/모바일 연동에서는 “기능 구현”뿐 아니라 **인증/동기화 자동화**가 사용자 경험을 크게 좌우한다는 걸 배웠습니다.
* 외부 API만 쓰는 것보다, 온프레미스 LLM을 구성하면 **개인정보/비용/확장성** 측면에서 장점이 크다는 점을 체감했습니다.
* RAG, 스트리밍, 양자화(AWQ) 같은 기법을 실제 서비스 형태로 묶어보며 **AI 시스템을 제품 수준으로 구성하는 경험**을 얻었습니다.

---

## 📌 향후 개선 아이디어

* 질문 히스토리/북마크 기능
* 사용자 맞춤 프롬프트/페르소나 설정
* RAG 문서 업데이트 자동화 및 검색 품질 개선
* 워치 입력 UX(음성 인식/제스처) 정확도 개선
